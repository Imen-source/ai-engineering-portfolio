# AI Engineering Portfolio

This repository is a curated **AI Engineering portfolio** showcasing hands-on projects in **machine learning, deep learning, and large language models (LLMs)**.

It is designed to demonstrate:
- Practical understanding of modern AI tools
- Clean, reproducible experimentation
- Engineering-oriented thinking (not just coursework)

> ğŸ“Œ **Note**: Large datasets and trained models are intentionally excluded to follow GitHub best practices. All notebooks are fully reproducible.

---

## ğŸ§  Project Structure

ai-engineering-portfolio/
â”‚
â”œâ”€â”€ pytorch/
â”‚ â”œâ”€â”€ cnn_fashion_mnist.ipynb
â”‚ â””â”€â”€ cnn_image_classifier.ipynb
â”‚
â”œâ”€â”€ transformers/
â”‚ â””â”€â”€ text_classification_transformers.ipynb
â”‚
â”œâ”€â”€ rag-langchain/
â”‚ â””â”€â”€ document_qa_rag.ipynb
â”‚
â”œâ”€â”€ llms/
â”‚ â””â”€â”€ prompt_engineering_basics.md
â”‚
â””â”€â”€ README.md

yaml
Copy code

---

## ğŸ”¥ Key Projects

### 1ï¸âƒ£ PyTorch â€“ Deep Learning Fundamentals
**Folder:** `pytorch/`

- Implemented **CNNs from scratch** using PyTorch
- Worked with image classification pipelines
- Focused on:
  - Model architecture design
  - Training loops
  - Evaluation metrics
  - Overfitting & generalization

ğŸ“Œ Datasets (Fashion-MNIST, CIFAR-10) are downloaded programmatically inside notebooks.

---

### 2ï¸âƒ£ Transformers â€“ Text Classification
**Folder:** `transformers/`

- Fine-tuned **DistilBERT** for text classification
- Used Hugging Face `Trainer` API
- Implemented:
  - Tokenization
  - Dataset preprocessing
  - Training & evaluation
  - Accuracy-based performance analysis

ğŸ“Œ Demonstrates real-world NLP workflow using production-grade libraries.

---

### 3ï¸âƒ£ RAG (Retrieval-Augmented Generation)
**Folder:** `rag-langchain/`

- Built a **Document Question Answering system**
- Combined:
  - Document loaders
  - Embeddings
  - Vector search
  - LLM-based answer generation

ğŸ“Œ Focused on *LLM application architecture*, not just prompts.

---

### 4ï¸âƒ£ LLMs â€“ Prompt Engineering
**Folder:** `llms/`

- Practical notes on **prompt engineering fundamentals**
- Covers:
  - Prompt structure
  - Instruction clarity
  - Few-shot vs zero-shot prompting
  - Common pitfalls

ğŸ“Œ Written as an engineering reference, not theory notes.

---

## ğŸ›  Tech Stack

- **Languages:** Python
- **Frameworks:** PyTorch, Hugging Face Transformers
- **LLMs:** DistilBERT, OpenAI-compatible models
- **RAG:** LangChain
- **Tools:** Google Colab, Git, GitHub

---

## ğŸ§ª Reproducibility

All notebooks:
- Download datasets programmatically
- Avoid committing large files
- Can be executed end-to-end in **Google Colab** or locally

---

## ğŸ¯ Purpose of This Repository

This portfolio was built to:
- Prepare for **AI / ML / LLM internships**
- Demonstrate **practical engineering skills**
- Show ability to learn, debug, and ship working AI systems

It reflects **how I think and work**, not just what I studied.

---






